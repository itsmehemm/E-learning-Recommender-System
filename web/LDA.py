from nltk.tokenize import RegexpTokenizer
from stop_words import get_stop_words
from nltk.stem.porter import PorterStemmer
from flask import Flask, jsonify, redirect, url_for, request, render_template
from gensim import corpora, models
from sklearn.metrics.pairwise import cosine_similarity
from scipy import sparse
import gensim
import pandas as pd
import xlrd
import MySQLdb
import numpy as np
import pymysql
import pyLDAvis.gensim
import pyLDAvis.gr11111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111235/******************************************1tebook()111*/////////////////////////////////////////////////////////////////////////////////////////////////1111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111111/*/*//////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////*/
topics_total = 30
users_total = 4
tokenizer = RegexpTokenizer(r'\w+')
en_stop = get_stop_words('en')
p_stemmer = PorterStemmer()

print("Questions database is being read..")
questions = pd.read_excel('/home/hemm/Desktop/Final Year Project/web/Datasets/posts.xls')
print("Questions are successfully imported.")

print("Total Number of questions in the forum: %d" % (questions['TITLE'].size))

doc_set = []
for i in range(0, questions['TITLE'].size):
	doc_set.append(questions['TITLE'][i])

texts = []
for i in doc_set:
    raw = i.lower()
    tokens = tokenizer.tokenize(raw)
    stopped_tokens = [i for i in tokens if not i in en_stop]
    #stemmed_tokens = [p_stemmer.stem(i) for i in stopped_tokens]
    texts.append(stopped_tokens)
    #texts.append(stemmed_tokens)
print("Stemmed Tokens from the questions: ")
print(texts)

dictionary = corpora.Dictionary(texts)
corpus = [dictionary.doc2bow(text) for text in texts]
ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics=topics_total, id2word = dictionary, passes=1)
print("The topics under which the questions lies are: ")
print(ldamodel.print_topics(num_topics=topics_total, num_words=4))

topic = []
topic_temp = []
topic_token = []
for i in range(0, topics_total):
	print("Topic # %d: " % i)
	topic = ldamodel.show_topic(topicid=i, topn=4)
	print(topic)
	topic_temp.append(topic[0][0])
	topic_temp.append(topic[1][0])
	topic_temp.append(topic[2][0])
	topic_temp.append(topic[3][0])
	topic_token.append(topic_temp)
	topic_temp = []
	
print("Topic tokens seperated:")
print(topic_token)
	
similarity_matrix = []
new = []
for i in range(0, users_total):
	for j in range(0, topics_total):
		new.append(0)
	similarity_matrix.append(new)
	new = []

print("Initial Similarity matrix: ")
for i in range(0, users_total):
	print(similarity_matrix[i])
	print("\n")	
	
for i in range(0, users_total):
	for j in range(0, topics_total):
		for k in range(0, (questions['TITLE'].size)):
			if(questions['PARENTID'][k]-1 == i):
				for m in range(0, len(texts[k])):
					for n in range(0, len(topic_token[j])):
						if(texts[k][m] == topic_token[j][n]):
							similarity_matrix[i][j] = 1
							 
print("Processed similarity matrix: ")
for i in range(0, users_total):
	print(similarity_matrix[i])
	print("\n")
	
topic_matrix = similarity_matrix

A =  np.array(similarity_matrix)
A_sparse = sparse.csr_matrix(A)

similarities = cosine_similarity(A_sparse)
print('pairwise dense output:\n {}\n'.format(similarities))

similarities_sparse = cosine_similarity(A_sparse,dense_output=False)
print('pairwise sparse output:\n {}\n'.format(similarities_sparse))

#pyLDAvis.enable_notebook()
vis = pyLDAvis.gensim.prepare(ldamodel, corpus, dictionary)

#print(vis)
#pyLDAvis.save_html(vis, "ldaop.html")

unknown = []
temp_unknown = []
count_unknown = 0
for i in range(0, topics_total):
	if(topic_matrix[0][i]==0):
		temp_unknown.append(topic_token[i])
		unknown.append(temp_unknown)
		temp_unknown = []
		count_unknown = count_unknown + 1
		
print("\nPotential Topics of recommendations:\n")

for i in range(0, count_unknown):
	print(unknown[i])

checkbool=[]
for i in range(1, questions['TITLE'].size):
	checkbool.append(0) 



G=nx.Graph()
for i in range(0, users_total):
	for j in range(0, users_total):
		G.add_edge(i, j, weight=similarities[i][j])
		

elarge=[(u,v) for (u,v,d) in G.edges(data=True) if d['weight'] >0.95]
esmall=[(u,v) for (u,v,d) in G.edges(data=True) if d['weight'] <=0.95]

pos=nx.spring_layout(G) 

nx.draw_networkx_nodes(G,pos,node_size=700)

nx.draw_networkx_edges(G,pos,edgelist=elarge,
                    width=6)
nx.draw_networkx_edges(G,pos,edgelist=esmall,
                    width=6,alpha=0.5,edge_color='b',style='dashed')

nx.draw_networkx_labels(G,pos,font_size=20,font_family='sans-serif')

plt.axis('off')
labels = nx.get_edge_attributes(G,'weight')
nx.draw_networkx_edge_labels(G,pos,edge_labels=labels)
plt.savefig("static/images/graph.png") 

